{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc909aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import scipy.stats as stats\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dbd36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets grab our data from the pca transformation\n",
    "X_numpy = np.load('pca_transformed_data_v1.npy', allow_pickle=True)\n",
    "y_numpy = np.load('label.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9e21c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22d99f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X_numpy.astype(np.float32)).squeeze()\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee1fe088",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets split our data\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2,\n",
    "                                                                           random_state=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a64252ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#send the data into gpu\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "X_train,X_test, y_train,y_test = X_train.to(device), X_test.to(device), y_train.to(device), y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06663ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create a model for hyperparameter tuning\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(18, 34)\n",
    "        self.layer2 = nn.Linear(34, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        #add forward function\n",
    "    def forward(self, x):\n",
    "        return self.layer2(self.relu(self.layer1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b0895ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1605694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function & optimizer\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0009289305355089368, weight_decay=0.0007777563951641034)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49aba8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamincheng/miniforge3/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: The operator 'aten::sgn.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | train_loss: 0.6128159165382385 | test_loss: 0.6664394736289978 | test_spearman: -0.099776524575603\n",
      "Epoch: 465 | train_loss: 0.5653883218765259 | test_loss: 0.6251594424247742 | test_spearman: -0.03449278979753924\n",
      "Epoch: 930 | train_loss: 0.550709068775177 | test_loss: 0.6148455142974854 | test_spearman: 0.02469587499742863\n",
      "Epoch: 1395 | train_loss: 0.5447897911071777 | test_loss: 0.6096615791320801 | test_spearman: 0.06663051314952195\n",
      "Epoch: 1860 | train_loss: 0.5416805148124695 | test_loss: 0.6074155569076538 | test_spearman: 0.08413863197847828\n",
      "Epoch: 2325 | train_loss: 0.539467453956604 | test_loss: 0.6059355139732361 | test_spearman: 0.09103997327995379\n",
      "Epoch: 2790 | train_loss: 0.5379705429077148 | test_loss: 0.6045100688934326 | test_spearman: 0.09416449910173677\n",
      "Epoch: 3255 | train_loss: 0.536628782749176 | test_loss: 0.6032556295394897 | test_spearman: 0.09749822449721958\n",
      "Epoch: 3720 | train_loss: 0.5354858040809631 | test_loss: 0.6023893356323242 | test_spearman: 0.10372976802195658\n",
      "Epoch: 4185 | train_loss: 0.5344825983047485 | test_loss: 0.601808488368988 | test_spearman: 0.10801880820892706\n",
      "Epoch: 4650 | train_loss: 0.5336412787437439 | test_loss: 0.6015838384628296 | test_spearman: 0.11300458174006522\n",
      "Epoch: 5115 | train_loss: 0.5329467058181763 | test_loss: 0.601449728012085 | test_spearman: 0.11595896456092067\n",
      "Epoch: 5580 | train_loss: 0.5323324799537659 | test_loss: 0.6014261245727539 | test_spearman: 0.11912972977345704\n",
      "Epoch: 6045 | train_loss: 0.5318143963813782 | test_loss: 0.6012212038040161 | test_spearman: 0.1212239701410745\n",
      "Epoch: 6510 | train_loss: 0.5313326716423035 | test_loss: 0.6011072993278503 | test_spearman: 0.1222811911626692\n",
      "Epoch: 6975 | train_loss: 0.5309171080589294 | test_loss: 0.6010670065879822 | test_spearman: 0.12195571972290012\n",
      "Epoch: 7440 | train_loss: 0.5305401086807251 | test_loss: 0.6010605096817017 | test_spearman: 0.12293752115569313\n",
      "Epoch: 7905 | train_loss: 0.5301978588104248 | test_loss: 0.6011449694633484 | test_spearman: 0.1237123676454054\n",
      "Epoch: 8370 | train_loss: 0.5298641324043274 | test_loss: 0.6013143658638 | test_spearman: 0.1230039622220184\n",
      "Epoch: 8835 | train_loss: 0.5295655727386475 | test_loss: 0.6013376712799072 | test_spearman: 0.12387308319773274\n",
      "Epoch: 9300 | train_loss: 0.5292912721633911 | test_loss: 0.6014070510864258 | test_spearman: 0.12566699198851503\n"
     ]
    }
   ],
   "source": [
    "#train and test loop\n",
    "torch.mps.manual_seed(34)\n",
    "torch.manual_seed(110)\n",
    "\n",
    "epochs = 9308\n",
    "subset = int(epochs * 0.05)\n",
    "epoch_count = []\n",
    "training_loss = []\n",
    "testing_loss = []\n",
    "for epoch in range(epochs):\n",
    "    #turn on training mode\n",
    "    model.train()\n",
    "    \n",
    "    #fit data\n",
    "    train_pred = model(X_train)\n",
    "    \n",
    "    #calculate loss\n",
    "    train_loss = loss_fn(train_pred, y_train)\n",
    "    \n",
    "    #zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #back propagation\n",
    "    train_loss.backward()\n",
    "    \n",
    "    #gradient descent\n",
    "    optimizer.step()\n",
    "    \n",
    "    #testing\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_pred = model(X_test)\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "    \n",
    "    if epoch % subset == 0:\n",
    "        training_loss.append(train_loss)\n",
    "        epoch_count.append(epoch)\n",
    "        testing_loss.append(test_loss)\n",
    "        pred = test_pred.to('cpu')\n",
    "        accuracy = stats.spearmanr(y_test.to('cpu'),pred)\n",
    "        print(f'Epoch: {epoch} | train_loss: {train_loss} | test_loss: {test_loss} | test_spearman: {accuracy.statistic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57368ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
